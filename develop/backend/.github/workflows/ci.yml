# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will build a Java project with Gradle and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-java-with-gradle

name: Java CI with Gradle

on:
  push:
    branches: ["backend"]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: "11"
          distribution: "temurin"

      - name: Build with Gradle
        uses: gradle/gradle-build-action@67421db6bd0bf253fb4bd25b31ebb98943c375e1
        with:
          arguments: build

      - name: Deploy Docker to AWS (EC2)
        # You may pin to the exact commit or the version.
        # uses: bitovi/github-actions-deploy-docker-to-ec2@a07065c57654a20703b999a1f16b2730d54df8b9
        uses: bitovi/github-actions-deploy-docker-to-ec2@v0.5.2
        with:
          # Specifies if this action should checkout the code
          #         checkout: # optional, default is true
          # AWS access key ID
          aws_access_key_id: AKIAXTILBOBUPI46ZWES
          # AWS secret access key
          aws_secret_access_key: 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
          # AWS default region
          aws_default_region: ap-northeast-2
          # AWS AMI ID. Will default to the latest Ubuntu 22.04 server image (HVM)
          #         aws_ami_id: # optional
          # AWS S3 bucket to use for Terraform state. Defaults to `${org}-${repo}-{branch}-tf-state`
          #         tf_state_bucket: # optional
          # Force purge and deletion of S3 bucket defined. Any file contained there will be destroyed. `stack_destroy` must also be `true`
          #         tf_state_bucket_destroy: # optional, default is false
          # Set to override the AWS resource identifier for the deployment.  Defaults to `${org}-{repo}-{branch}`.  Use with destroy to destroy specific resources.
          #         aws_resource_identifier: # optional
          # File containing environment variables to be used with the app
          #         repo_env: # optional, default is repo_env
          # `.env` file to be used with the app from Github secrets
          #         dot_env: # optional
          # `.env` file to be used with the app from Github variables
          #         ghv_env: # optional
          # Secret name to pull env variables from AWS Secret Manager
          #         aws_secret_env: # optional, default is
          # Relative path for the directory of the app (i.e. where `Dockerfile` and `docker-compose.yaml` files are located). This is the directory that is copied to the EC2 instance.  Default is the root of the repo.
          #         app_directory: # optional
          # Port to expose for the app
          app_port: 8090 # optional
          # Load balancer listening port. Defaults to 80 if NO FQDN provided, 443 if FQDN provided
#         lb_port: # optional
#         # Load balancer health check string. Defaults to HTTP:app_port
#         lb_healthcheck: # optional
#         # The AWS IAM instance profile to use for the EC2 instance
#         ec2_instance_profile: # optional
#         # The AWS Instance type
#         ec2_instance_type: # optional
#         # The size of the volume (in GB) on the AWS Instance
#         ec2_volume_size: # optional, default is 8
#         # Toggle to indicate whether to create and EFS and mount it to the ec2 as a part of the provisioning. Note: The EFS will be managed by the stack and will be destroyed along with the stack
#         aws_create_efs: # optional
#         # Toggle to indicate whether the EFS resource should be highly available (target mounts in all available zones within region)
#         aws_create_ha_efs: # optional
#         # Toggle to indiciate whether a read-only replica should be created for the EFS primary file system
#         aws_create_efs_replica: # optional
#         # Toggle to indiciate whether the EFS should have a backup policy, default is `false`
#         aws_enable_efs_backup_policy: # optional
#         # Information on Zone Mapping can be found in the [README.md](README.md#efs-zone-mapping)
#         aws_efs_zone_mapping: # optional
#         # Indicates how long it takes to transition files to the IA storage class
#         aws_efs_transition_to_inactive: # optional
#         # AWS Region to target for replication
#         aws_replication_configuration_destination: # optional
#         # ID of existing EFS
#         aws_mount_efs_id: # optional
#         # ID of the primary security group used by the existing EFS
#         aws_mount_efs_security_group_id: # optional
#         # Set to "true" to Destroy the stack. Will delete the elb_logs bucket after the destroy action runs.
#         stack_destroy: # optional
#         # Define the root domain name for the application. e.g. app.com
#         domain_name: # optional
#         # Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`
#         sub_domain: # optional
#         # Deploy to root domain. Will generate two DNS recrods, one for root, another for www
#         root_domain: # optional
#         # Define the certificate ARN to use for the application
#         cert_arn: # optional
#         # Generates and manage the root cert for the application
#         create_root_cert: # optional
#         # Generates and manage the sub-domain certificate for the application
#         create_sub_cert: # optional
#         # Makes the application not to use a certificate by disabling certificate lookup.
#         no_cert: # optional
#         # A list of targets to create before the full stack creation. Example: `
#         targets: # optional
#         # A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`
#         additional_tags: # optional
#         # Generates and manages a secret manager entry that contains the public and private keys created for the ec2 instance.
#         create_keypair_sm_entry: # optional
#         # Set to "true" to enable a postgres database
#         aws_enable_postgres: # optional
#         # Which Database engine to use
#         aws_postgres_engine: # optional
#         # Specify Postgres version
#         aws_postgres_engine_version: # optional
#         # Define the size of the instances in the DB cluster
#         aws_postgres_instance_class: # optional
#         # Specify which subnets to use as a list of strings.  Example: `i-1234,i-5678,i-9101`
#         aws_postgres_subnets: # optional
#         # Specify a database name. Will be created if it does not exist
#         aws_postgres_database_name: # optional
#         # Postgres database port
#         aws_postgres_database_port: # optional
#         # Directory path in application env to mount directory, default is `data`
#         application_mount_target: # optional, default is data
#         # Directory path within docker env to mount directory to, default is `/data`
#         data_mount_target: # optional
#         # Directory path in efs to mount directory to, default is `/`
#         efs_mount_target: # optional
